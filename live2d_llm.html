<html>

<head>
  <script src="./js/live2dcubismcore.min.js"></script>
  <script src="./js/live2d.min.js"></script>
  <script src="./js/pixi.min.js"></script>
  <script src="./js/cubism4.min.js"></script>
  <script src="./js/jquery-3.1.1.min.js"></script>
  <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
</head>

<body>

  <style>
    /* CSS样式 */
    #input_audio {
      border-radius: 50%;
      width: 50px;
      height: 50px;
      background-color: #fff;
      /* 默认背景色 */
    }

    #input_audio:active {
      background-color: #ccc;
      /* 按下时的背景色 */
    }


    /* CSS样式 */
    #stop_audio {
      border-radius: 50%;
      width: 50px;
      height: 50px;
      background-color: #fff;
      /* 默认背景色 */
    }

    #stop_audio:active {
      background-color: #ccc;
      /* 按下时的背景色 */
    }

    .container {
      display: flex;
      flex-direction: column;
      align-items: flex-start;
      position: absolute;
      left: 180px;
      top: 50%;
      transform: translateY(-50%);
      z-index: 1;
    }

    .text-box {
      background-color: rgba(255, 255, 255, 0.8);
      padding: 20px;
      border-radius: 10px;
      font-family: 'Arial', sans-serif;
      font-size: 18px;
      color: #333;
      max-width: 300px;
      margin-bottom: 20px;
      /* 滚动条 */
      max-height: 200px;
      overflow-y: auto;
      scrollbar-width: none;
      /* 针对Firefox */
      -ms-overflow-style: none;
      /* 针对IE和Edge */
    }

    .text-box::-webkit-scrollbar {
      display: none;
      /* 针对Chrome, Safari和Opera */
    }

    .image-box {
      background-color: #fff;
      padding: 10px;
      border-radius: 10px;
      box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }

    .image-box img {
      max-width: 100%;
      height: auto;
      border-radius: 5px;
      width: 270px;
    }

    #canvas {
      background-image: url('./bg.png');
      background-size: cover;
      background-position: center;
    }
  </style>


  <div class="container">
    <div class="text-box">
      <p> One talk, World unlocked. </p>
    </div>
    <div class="image-box">
      <img id="image-to-update" src="logo.png" alt="预设图片">
    </div>
  </div>

  <canvas id="canvas"></canvas>

  <div id="control">
    <button id="play">测试音频</button>
    <br />
    <label>数字人模型</label>
    <select id="model_list"></select>
    <button id="update_model">更新模型</button>
    <br />
    <label>眼神跟随鼠标</label>
    <input type="radio" name="eyes" value="true" checked>
    <label>跟随鼠标</label>
    <input type="radio" id="option2" name="eyes" value="false">
    <label>前方直视</label>
    <br />
    <label>背景控制</label>
    <input type="radio" id="option1" name="options" value="bg_color">
    <label for="option1">背景颜色</label>
    <input id="bg_color" type="text" style="width:100px;">
    <!-- <br /> -->
    <input type="radio" id="option2" name="options" value="bg_img" checked>
    <label for="option2">背景图片</label>
    <button id="update_bg">更新背景</button>
    <br />
    <label>语言选择</label>
    <select id="languageSelect">
      <option value="ZH">中文</option>
      <option value="JA">日本語</option>
      <option value="EN">English</option>
    </select>
    <button id="languageUpdate">更新语言</button>
    <br />

    <!-- Circle Button for Audio Input -->
    <button id="input_audio" style="border-radius: 50%; width: 50px; height: 50px;">🎤</button>
    <button id="stop_audio" style="border-radius: 50%; width: 50px; height: 50px;">⭕</button>
    <!-- <button id="start_recording">开始录音</button>
    <button id="stop_recording" disabled>停止录音</button> -->


    <br />

    <!-- 在HTML中添加按钮 -->
    <button id="tearBtn">Tear</button>
    <button id="angryBtn">Angry</button>
    <button id="despairBtn">Despair</button>
    <button id="happyBtn">Happy</button>
    <button id="panicBtn">Panic</button>


  </div>

  <script type="text/javascript">

    $('input[name="eyes"]').click(function () {
      var radioValue = $("input[name='eyes']:checked").val();
      setCookie("eyes", radioValue, 1024);
      location.reload();
    });



    function getCookie(name) {
      const value = "; " + document.cookie;
      const parts = value.split("; " + name + "=");
      if (parts.length === 2) return parts.pop().split(";").shift();
    }

    function setCookie(name, value, days) {
      const date = new Date();
      date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
      const expires = "expires=" + date.toUTCString();
      document.cookie = name + "=" + value + ";" + expires + ";path=/";
    }

    const selectedValue = getCookie("bg_con");
    if (selectedValue) {
      const radioButtons = document.getElementsByName("options");
      radioButtons.forEach(radio => {
        radio.checked = false;
        if (radio.value === selectedValue) {
          radio.checked = true;
        }
      });
    }

    const eyesValue = getCookie("eyes");
    if (eyesValue) {
      const radioButtons = document.getElementsByName("eyes");
      radioButtons.forEach(radio => {
        radio.checked = false;
        if (radio.value == eyesValue) {
          radio.checked = true;
        }
      });
    }

    let radioValue = $("input[name='options']:checked").val();
    if (getCookie("bg_color") === undefined) { $("#bg_color").val("gray"); } else { $("#bg_color").val(getCookie("bg_color")); }
    if (radioValue == "bg_color") {
      $("#canvas").css("background-color", $("#bg_color").val());
    } else {
      if (getCookie("bg_img") !== undefined) {
        let imageUrl = "./uploads/" + getCookie("bg_img");
        $("#canvas").css("background-image", "url(" + imageUrl + ")");
      }
    }

    let eye_bool = true;
    if (getCookie("eyes") === undefined) { } else {
      if (getCookie("eyes") == "false") {
        eye_bool = false;
      }
    }

    var cubism4Model = './models/<%=model_path%>/<%=model_path%>.model3.json';
    var selected_model = '<%-model_path%>';
    var model_list = '<%-model_list%>';
    model_list = JSON.parse(model_list);

    var $select = $("#model_list");
    $select.empty();
    $.each(model_list, function (index, value) {
      if (value == selected_model) {
        $select.append($("<option selected></option>").attr("value", value).text(value));
      } else {
        $select.append($("<option></option>").attr("value", value).text(value));
      }
    });

    const live2d = PIXI.live2d;

    (async function main() {
      const app = new PIXI.Application({
        view: document.getElementById("canvas"),
        autoStart: true,
        resizeTo: window,
        transparent: true,
        backgroundAlpha: 0,
      });
      // web环境中没有process
      // const azure_key = process.env.AZURE_KEY;
      // 将特殊字符转换为对应的 HTML 实体,这是为了防止 XSS（跨站脚本）攻击
      // const azure_key = '<%= process.env.AZURE_KEY %>';
      // 如下方式,就没有转义的过程了
      const azure_key = '<%- process.env.AZURE_KEY %>';
      console.log("___________________", azure_key)

      const azure_region = "japaneast";
      const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(azure_key, azure_region);
      // speechConfig.speechSynthesisLanguage = "ja-JP";
      // speechConfig.speechSynthesisVoiceName = "ja-JP-NanamiNeural";

      // 根据选择的语言设置语音合成参数
      let speechSynthesizer;
      function updateSpeechConfig() {
        const languageSelect = document.getElementById('languageSelect');
        const selectedLanguage = languageSelect.value;

        switch (selectedLanguage) {
          case 'ZH':
            speechConfig.speechSynthesisLanguage = 'zh-CN';
            speechConfig.speechSynthesisVoiceName = 'zh-CN-XiaoxiaoNeural';
            break;
          case 'JA':
            speechConfig.speechSynthesisLanguage = 'ja-JP';
            speechConfig.speechSynthesisVoiceName = 'ja-JP-NanamiNeural';
            break;
          case 'EN':
            speechConfig.speechSynthesisLanguage = 'en-US';
            speechConfig.speechSynthesisVoiceName = 'en-US-JennyNeural';
            break;
          default:
            break;
        }
        console.log("Re-create the speechSynthesizer, language:", selectedLanguage)
        // 重新创建 speechSynthesizer 实例
        speechSynthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, null);
      }

      // 初始化时调用一次
      updateSpeechConfig();

      // const audioConfig = SpeechSDK.AudioConfig.fromDefaultSpeakerOutput();
      // const speechSynthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, audioConfig);
      // const speechSynthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, null); // 不指定audioConfig，使其不自动播放


      let audioContext = new (window.AudioContext || window.webkitAudioContext)();
      let audioBuffer = null;
      let audioSource = null;
      let offset = 0;

      // AutoInteract has been abandoned
      // var models = await Promise.all([
      //   live2d.Live2DModel.from(cubism4Model, { autoInteract: eye_bool })
      // ]);
      var models = await Promise.all([
        live2d.Live2DModel.from(cubism4Model, {
          autoHitTest: eye_bool,
          autoFocus: eye_bool
        })
      ]);
      PIXI.live2d.models = models;

      models.forEach((model) => {
        app.stage.addChild(model);
        const scaleX = (innerWidth) / model.width;
        const scaleY = (innerHeight) / model.height;
        model.scale.set(Math.min(scaleX, scaleY));
        model.y = innerHeight * 0.1;
        draggable(model);
      });

      const model4 = models[0];
      model4.x = innerWidth / 2;

      model4.on("hit", (hitAreas) => {
        if (hitAreas.includes("Body")) {
          model4.motion("Tap");
        }
        if (hitAreas.includes("Head")) {
          model4.expression();
        }
      });

      const internalModel = model4.internalModel;
      console.log('Available expressions:', internalModel.settings.expressions);
      console.log('Available motions:', internalModel.settings.motions);

      const expressionMap = {
        Tear: 'Sad.exp3.json',
        Angry: 'Angry.exp3.json',
        Despair: 'Dispair.exp3.json',
        Happy: 'Happy.exp3.json',
        Panic: 'Shock.exp3.json'
      };

      const motionMap = {
        Tear: 'motions/haru_g_m26.motion3.json',
        Angry: 'motions/haru_g_m06.motion3.json',
        Despair: 'motions/haru_g_m20.motion3.json',
        Happy: 'motions/haru_g_m09.motion3.json',
        Panic: 'motions/mtn_03.motion3.json'
      };

      // 获取按钮元素
      const tearBtn = document.getElementById('tearBtn');
      const angryBtn = document.getElementById('angryBtn');
      const despairBtn = document.getElementById('despairBtn');
      const happyBtn = document.getElementById('happyBtn');
      const panicBtn = document.getElementById('panicBtn');

      // 为按钮添加点击事件监听器
      tearBtn.addEventListener('click', () => triggerExpression('Tear'));
      angryBtn.addEventListener('click', () => triggerExpression('Angry'));
      despairBtn.addEventListener('click', () => triggerExpression('Despair'));
      happyBtn.addEventListener('click', () => triggerExpression('Happy'));
      panicBtn.addEventListener('click', () => triggerExpression('Panic'));


      // 表情会随着音频播放完成而回到默认,考虑对此进行控制
      function triggerExpression(expressionName) {
        if (model4) {
          const internalModel = model4.internalModel;
          const expressionFile = expressionMap[expressionName];
          if (expressionFile) {
            const expressions = internalModel.settings.expressions;
            const expression = expressions.find(expr => expr.File.endsWith(expressionFile));
            if (expression) {
              // // apply the first expression
              // model.expression(0);
              // // apply the expression named "smile"
              // model.expression('smile');
              model4.expression(expression.Name);
              // model.internalModel.motionManager.expressionManager.setExpression('smile');
              console.log(`Expression ${expression.Name} triggered.`);
            } else {
              console.log(`Expression file ${expressionFile} not found.`);
            }
          } else {
            console.log(`No expression mapped for ${expressionName}.`);
          }
        } else {
          console.log('Live2D model not loaded.');
        }
      }

      function triggerMotion(motionName) {
        if (model4) {
          const internalModel = model4.internalModel;

          // 检查是否存在动作列表
          if (internalModel.settings.motions && Object.keys(internalModel.settings.motions).length > 0) {
            // https://guansss.github.io/pixi-live2d-display/motions_expressions/
            const motionFile = motionMap[motionName];
            if (motionFile) {
              console.log(internalModel);
              const motionManager = internalModel.motionManager;
              const motionGroups = internalModel.settings.motions;

              // 获取动作文件名
              const motionFileName = motionFile.split('/').pop();

              // 查找包含动作文件的组名
              const motionGroupName = Object.keys(motionGroups).find(groupName =>
                motionGroups[groupName].some(motion => motion.File.endsWith(motionFileName))
              );

              if (motionGroupName) {
                const motionIndex = motionGroups[motionGroupName].findIndex(motion => motion.File.endsWith(motionFileName));
                if (motionIndex !== -1) {
                  // 动作会有搭配的音频，如下方式禁用动作音频其实会导致正常lip sync的音频也没办法播放，所以最好的方式是直接去修改motion的动作文件。后续的demo可以说明可以调用动作，但是用expression演示，问题会少很多。
                  // // 临时禁用声音
                  // const motion = motionGroups[motionGroupName][motionIndex];
                  // const originalSound = motion.Sound; // 假设Sound是声音属性
                  // // 移除声音
                  // motion.Sound = null;
                  // // 恢复声音
                  // motion.Sound = originalSound;

                  // start the first motion in "tap_body" group
                  // model.motion('tap_body', 0);
                  // the above calls are shorthands of these methods
                  // 0: 最低优先级, 通常用于闲置或待机状态下的动作。
                  // 1: 普通优先级, 用于一般的动作。
                  // 2: 较高优先级, 用于重要的动作或需要立即响应的动作。
                  // 3: 最高优先级, 用于最重要或紧急的动作, 会中断其他所有动作并立即执行。
                  motionManager.startMotion(motionGroupName, motionIndex, 3);
                  console.log(`Motion ${motionFileName} triggered in group ${motionGroupName}.`);
                  // 恢复声音
                  motion.Sound = originalSound;
                } else {
                  console.log(`Motion file ${motionFileName} not found in group ${motionGroupName}.`);
                }
              } else {
                console.log(`Motion file ${motionFileName} not found in any group.`);
              }
            } else {
              console.log(`No motion mapped for ${motionName}.`);
            }
          } else {
            console.log('No motions available for this model.');
          }
        } else {
          console.log('Live2D model not loaded.');
        }
      }

      $("#update_bg").click(function () {
        var radioValue = $("input[name='options']:checked").val();
        setCookie("bg_con", radioValue, 1024);

        if (radioValue === "bg_color") {
          setCookie("bg_color", $("#bg_color").val(), 1024);
          $("#canvas").css("background-image", "none");
          $("#canvas").css("background-color", $("#bg_color").val());
        } else if (radioValue === "bg_img") {
          setCookie("bg_color", "");
          $("#canvas").css("background-color", "transparent");
          $("#canvas").css("background-image", "url('./bg.png')");
          $("#canvas").css("background-size", "cover");
          $("#canvas").css("background-position", "center");
        }
      });

      // $("#update_bg").click(function () {
      //   var radioValue = $("input[name='options']:checked").val();
      //   setCookie("bg_con", radioValue, 1024);
      //   setCookie("bg_color", $("#bg_color").val(), 1024);
      //   location.reload();
      // });

      // 当语言选择发生变化时,更新语音合成配置
      // $('#languageSelect').change(function () {
      //   updateSpeechConfig();
      // });
      $('#languageUpdate').click(function () {
        updateSpeechConfig();
      });

      $("#update_model").click(function () {
        axios.get('/edit_config', {
          params: { "model_path": $("#model_list").val() }
        })
          .then(response => {
            console.log(response.data);
            location.reload();
          })
          .catch(error => {
            console.error(error);
            alert(error);
          });
      });

      $("#play").click(function () {
        talk(model4, "./Keira.wav");
      });

      $('#stop_audio').click(function () {
        stopAudio();
        console.log("Stop streaming audio.")
      });

      // 当按下 "Ctrl" 键时触发
      $(document).keydown(function (event) {
        if (event.which === 17) {
          $("#input_audio").mousedown();
        }
      });

      // 当释放 "Ctrl" 键时触发
      $(document).keyup(function (event) {
        if (event.which === 17) {
          $("#input_audio").mouseup();
        }
      });

      let mediaRecorder;
      let chunks = [];

      $("#input_audio").mousedown(function () {
        $(this).addClass("pressed").removeClass("released");

        navigator.mediaDevices.getUserMedia({ audio: true })
          .then(stream => {
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.start();

            const timeout = setTimeout(() => {
              mediaRecorder.stop();
              stream.getTracks().forEach(track => track.stop());
            }, 10000);

            mediaRecorder.addEventListener('dataavailable', event => {
              chunks.push(event.data);
            });

            mediaRecorder.addEventListener('stop', () => {
              clearTimeout(timeout);
              const audioBlob = new Blob(chunks, { type: 'audio/wav' });
              chunks = [];
              getText(audioBlob)

              // Play the audio by Live2D
              // const audioUrl = URL.createObjectURL(audioBlob);
              // const model4 = PIXI.live2d.models[0];
              // talk(model4, audioUrl);
            });
          })
          .catch(error => {
            console.error('Error accessing microphone:', error);
          });
      });

      $("#input_audio").mouseup(function () {
        $(this).addClass("released").removeClass("pressed");

        if (mediaRecorder && mediaRecorder.state === 'recording') {
          mediaRecorder.stop();
          // 发送音频文件给接口
          // sendAudioToServer();
        }
      });

      // // 更新表情 todo
      // const changeExpression = (expressionName) => {
      //   if (window.live2dModel) {
      //     const expressions = window.live2dModel.internalModel.settings.expressions;
      //     const expression = expressions.find(expr => expr.name === expressionName);
      //     if (expression) {
      //       window.live2dModel.expression = expression;
      //     }
      //   }
      // }
      // // 更新动作 todo
      // function triggerMotion(motionGroup, motionName) {
      //   if (window.live2dModel) {
      //     window.live2dModel.internalModel.motionManager.startMotion(motionGroup, motionName);
      //   }
      // }


      const updateImage = (newSrc) => {
        if (newSrc !== "N") {
          const imgElement = document.getElementById('image-to-update');
          const encodedSrc = encodeURIComponent(newSrc);
          const imagePath = `./extracted_images/${encodedSrc}.png`;
          imgElement.src = imagePath;
        }
        // else {
        //   imgElement.src = "logo.png";
        // }
      };

      const getText = async (audioBlob) => {
        const formData = new FormData();
        formData.append('audio', audioBlob, 'audio.wav');
        // 传语言类型
        const languageSelect = document.getElementById('languageSelect');
        const selectedLanguage = languageSelect.value;
        formData.append('language', selectedLanguage);

        // 在发送请求之前清空文本框
        const textBox = document.querySelector('.text-box p');
        textBox.textContent = '';

        const response = await fetch('http://localhost:8080/process_audio', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error('Network response was not ok');
        }

        console.log("Call LLM done___");
        const textStream = response.body;
        await processText(textStream);
      };

      const processText = async (textStream) => {
        isProcessing = true;

        const textReader = textStream.getReader();
        const decoder = new TextDecoder('utf-8');
        let done = false;
        // Extract Title
        let title = '';
        let isFirstChunk = true;

        while (!done && isProcessing) {
          const { value, done: doneReading } = await textReader.read();
          done = doneReading;
          const chunk = decoder.decode(value, { stream: true });

          if (!title) {
            const separatorIndex = chunk.indexOf('|');
            if (separatorIndex !== -1) {
              title = chunk.slice(0, separatorIndex).trim();
              console.log('Title:', title); // 在控制台输出标题
              updateImage(title)
            }
          }
          // console.log(chunk);

          if (isFirstChunk) {
            isFirstChunk = false; // 跳过第一个块
          } else {
            if (chunk.trim() !== '') {
              await handleTextChunk(chunk.trim());
            }
          }
        }
      };

      let audioQueue = [];
      let isPlaying = false;

      // To stop audio streaming
      let isProcessing = false;
      const stopAudio = () => {
        isProcessing = false;
        audioQueue = [];
      };

      const handleTextChunk = async (text) => {
        const textBox = document.querySelector('.text-box p');
        textBox.textContent += text;

        const model4 = PIXI.live2d.models[0];

        const audioUrl = await synthesizeAudio(text);
        if (audioUrl !== null) {
          audioQueue.push(audioUrl);
          if (!isPlaying) {
            playNextAudio(model4);
          }
        }
      };

      const synthesizeAudio = async (text) => {
        return new Promise((resolve) => {
          speechSynthesizer.speakTextAsync(
            text,
            async (result) => {
              if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                console.log('Speech synthesis completed.');
                const audioBuffer = await audioContext.decodeAudioData(result.audioData);
                const audioUrl = await audioBufferToUrl(audioBuffer);
                resolve(audioUrl);
              }
            },
            (error) => {
              console.error(`Speech synthesis error: ${error}`);
              resolve(null);
            }
          );
        });
      };

      const playNextAudio = (model) => {
        if (audioQueue.length === 0) {
          isPlaying = false;
          return;
        }

        isPlaying = true;
        const audioUrl = audioQueue.shift();

        // const audio = new Audio(audioUrl);

        talk(model, audioUrl, () => {
          console.log('Audio finished');

          setTimeout(() => {
            playNextAudio(model);
          }, 100);
          // playNextAudio(model);
        });

        // 双重播放
        // audio.onended = () => {
        //   playNextAudio(model);
        // };
        // audio.muted = true; // 将音频设置为静音
        // talk(model, audioUrl);
        // audio.play();
      };

      const audioBufferToUrl = async (audioBuffer) => {
        const wav = audioBufferToWav(audioBuffer);
        const blob = new Blob([wav], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);
        return url;
      };

      const audioBufferToWav = (buffer) => {
        const numOfChan = buffer.numberOfChannels;
        const length = buffer.length * (numOfChan === 2 ? 4 : 2) + 44;
        const bufferInfo = new ArrayBuffer(length);
        const view = new DataView(bufferInfo);
        const channels = [];
        let offset = 0;
        let pos = 0;

        // write WAVE header
        writeUint32(0x46464952); // "RIFF"
        writeUint32(length - 8); // file length - 8
        writeUint32(0x45564157); // "WAVE"

        writeUint32(0x20746d66); // "fmt " chunk
        writeUint32(16); // length = 16
        writeUint16(1); // PCM (uncompressed)
        writeUint16(numOfChan);
        writeUint32(buffer.sampleRate);
        writeUint32(buffer.sampleRate * (numOfChan === 2 ? 4 : 2)); // avg. bytes/sec
        writeUint16(numOfChan === 2 ? 4 : 2); // block-align
        writeUint16(16); // 16-bit (hardcoded in this demo)

        writeUint32(0x61746164); // "data" - chunk
        writeUint32(length - pos - 4); // chunk length

        // write interleaved data
        for (let i = 0; i < numOfChan; i++) {
          channels.push(buffer.getChannelData(i));
        }

        while (pos < length) {
          for (let i = 0; i < numOfChan; i++) {
            // interleave channels
            let sample = Math.max(-1, Math.min(1, channels[i][offset])); // clamp
            sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0; // scale to 16-bit signed int
            view.setInt16(pos, sample, true); // write 16-bit sample
            pos += 2;
          }
          offset++; // next source sample
        }

        return bufferInfo;

        function writeUint16(data) {
          view.setUint16(pos, data, true);
          pos += 2;
        }

        function writeUint32(data) {
          view.setUint32(pos, data, true);
          pos += 4;
        }
      };

      // const talk = (model, audioUrl) => {
      //   var volume = 1;
      //   var expression = 8;
      //   var resetExpression = true;
      //   var crossOrigin = "anonymous";

      //   model.speak(audioUrl, { volume: volume, expression: expression, resetExpression: resetExpression, crossOrigin: crossOrigin });
      // };

      const talk = (model, audioUrl, onFinish) => {
        var volume = 1;
        var expression = 8;
        var resetExpression = true;
        var crossOrigin = "anonymous";

        model.speak(audioUrl, {
          volume: volume,
          expression: expression,
          resetExpression: resetExpression,
          crossOrigin: crossOrigin,
          onFinish: onFinish
        });
      };


      const synthesizer = {
        speakTextAsync: async (text) => {
          return new Promise((resolve, reject) => {
            speechSynthesizer.speakTextAsync(
              text,
              async (result) => {
                if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                  const audioBuffer = await audioContext.decodeAudioData(result.audioData);
                  resolve({ audioBuffer });
                } else {
                  reject(new Error(`Speech synthesis failed: ${result.errorDetails}`));
                }
              },
              (error) => {
                reject(new Error(`Speech synthesis error: ${error}`));
              }
            );
          });
        }
      };


    })();


    // function talk(model, audio) {
    //   var audio_link = audio;
    //   var volume = 1;
    //   var expression = 8;
    //   var resetExpression = true;
    //   var crossOrigin = "anonymous";

    //   model.speak(audio_link, { volume: volume, expression: expression, resetExpression: resetExpression, crossOrigin: crossOrigin })
    //   model.speak(audio_link)
    //   model.speak(audio_link, { volume: volume })
    //   model.speak(audio_link, { expression: expression, resetExpression: resetExpression })
    // }

    function draggable(model) {
      model.buttonMode = true;
      model.on("pointerdown", (e) => {
        model.dragging = true;
        model._pointerX = e.data.global.x - model.x;
        model._pointerY = e.data.global.y - model.y;
      });
      model.on("pointermove", (e) => {
        if (model.dragging) {
          model.position.x = e.data.global.x - model._pointerX;
          model.position.y = e.data.global.y - model._pointerY;
        }
      });
      model.on("pointerupoutside", () => {
        model.dragging = false;
      });
      model.on("pointerup", () => {
        model.dragging = false;
      });
    }
  </script>
</body>

</html>