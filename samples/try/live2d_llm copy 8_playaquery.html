<html>

<head>
  <script src="./js/live2dcubismcore.min.js"></script>
  <script src="./js/live2d.min.js"></script>
  <script src="./js/pixi.min.js"></script>
  <script src="./js/cubism4.min.js"></script>
  <script src="./js/jquery-3.1.1.min.js"></script>
  <script src="https://unpkg.com/axios/dist/axios.min.js"></script>
  <script src="https://aka.ms/csspeech/jsbrowserpackageraw"></script>
</head>

<body>

  <style>
    /* CSS样式 */
    #input_audio {
      border-radius: 50%;
      width: 50px;
      height: 50px;
      background-color: #fff;
      /* 默认背景色 */
    }

    #input_audio:active {
      background-color: #ccc;
      /* 按下时的背景色 */
    }
  </style>

  <canvas id="canvas"></canvas>

  <div id="control">
    <button id="play">测试音频</button>
    <br />
    <label>数字人模型</label>
    <select id="model_list"></select>
    <button id="update_model">更新模型</button>
    <br />
    <label>眼神跟随鼠标</label>
    <input type="radio" name="eyes" value="true" checked>
    <label>跟随鼠标</label>
    <input type="radio" id="option2" name="eyes" value="false">
    <label>前方直视</label>
    <br />
    <label>背景控制</label>
    <input type="radio" id="option1" name="options" value="bg_color" checked>
    <label for="option1">背景颜色</label>
    <input id="bg_color" type="text" style="width:100px;">
    <br />
    <input type="radio" id="option2" name="options" value="bg_img">
    <label for="option2">背景图片</label>
    <input type="file" id="imgupload" style="display:none" />
    <button id="openImgUpload">上传图片</button>
    <button id="update_bg">更新背景</button>
    <br />

    <!-- Circle Button for Audio Input -->
    <button id="input_audio" style="border-radius: 50%; width: 50px; height: 50px;">🎤</button>
    <!-- <button id="start_recording">开始录音</button>
    <button id="stop_recording" disabled>停止录音</button> -->

  </div>

  <script type="text/javascript">

    $('input[name="eyes"]').click(function () {
      var radioValue = $("input[name='eyes']:checked").val();
      setCookie("eyes", radioValue, 1024);
      location.reload();
    });

    $('#openImgUpload').click(function () {
      $('#imgupload').trigger('click');
    });

    $('#imgupload').on('change', function () {
      var formData = new FormData();
      formData.append('image', $(this)[0].files[0]);

      $.ajax({
        url: '/upload',
        type: 'POST',
        data: formData,
        processData: false,
        contentType: false,
        success: function (data) {
          console.log('上传成功: ', data.filename);
          setCookie("bg_img", data.filename, 1024);
          var radioValue = $("input[name='options']:checked").val();
          setCookie("bg_con", radioValue, 1024);
          location.reload();
        }
      });
    });

    function getCookie(name) {
      const value = "; " + document.cookie;
      const parts = value.split("; " + name + "=");
      if (parts.length === 2) return parts.pop().split(";").shift();
    }

    function setCookie(name, value, days) {
      const date = new Date();
      date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));
      const expires = "expires=" + date.toUTCString();
      document.cookie = name + "=" + value + ";" + expires + ";path=/";
    }

    const selectedValue = getCookie("bg_con");
    if (selectedValue) {
      const radioButtons = document.getElementsByName("options");
      radioButtons.forEach(radio => {
        radio.checked = false;
        if (radio.value === selectedValue) {
          radio.checked = true;
        }
      });
    }

    const eyesValue = getCookie("eyes");
    if (eyesValue) {
      const radioButtons = document.getElementsByName("eyes");
      radioButtons.forEach(radio => {
        radio.checked = false;
        if (radio.value == eyesValue) {
          radio.checked = true;
        }
      });
    }

    let radioValue = $("input[name='options']:checked").val();
    if (getCookie("bg_color") === undefined) { $("#bg_color").val("gray"); } else { $("#bg_color").val(getCookie("bg_color")); }
    if (radioValue == "bg_color") {
      $("#canvas").css("background-color", $("#bg_color").val());
    } else {
      if (getCookie("bg_img") !== undefined) {
        let imageUrl = "./uploads/" + getCookie("bg_img");
        $("#canvas").css("background-image", "url(" + imageUrl + ")");
      }
    }

    let eye_bool = true;
    if (getCookie("eyes") === undefined) { } else {
      if (getCookie("eyes") == "false") {
        eye_bool = false;
      }
    }

    var cubism4Model = './models/<%=model_path%>/<%=model_path%>.model3.json';
    var selected_model = '<%-model_path%>';
    var model_list = '<%-model_list%>';
    model_list = JSON.parse(model_list);

    var $select = $("#model_list");
    $select.empty();
    $.each(model_list, function (index, value) {
      if (value == selected_model) {
        $select.append($("<option selected></option>").attr("value", value).text(value));
      } else {
        $select.append($("<option></option>").attr("value", value).text(value));
      }
    });

    const live2d = PIXI.live2d;

    (async function main() {
      const app = new PIXI.Application({
        view: document.getElementById("canvas"),
        autoStart: true,
        resizeTo: window,
        transparent: true,
        backgroundAlpha: 0,
      });

      const azure_key = "ca8a3d705f2c45248f11f9e253a1969a";
      const azure_region = "japaneast";
      const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(azure_key, azure_region);
      speechConfig.speechSynthesisLanguage = "en-US";
      speechConfig.speechSynthesisVoiceName = "en-US-JennyNeural";

      // const audioConfig = SpeechSDK.AudioConfig.fromDefaultSpeakerOutput();
      // const speechSynthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, audioConfig);
      const speechSynthesizer = new SpeechSDK.SpeechSynthesizer(speechConfig, null); // 不指定audioConfig，使其不自动播放


      let audioContext = new (window.AudioContext || window.webkitAudioContext)();
      let audioBuffer = null;
      let audioSource = null;
      let offset = 0;

      var models = await Promise.all([
        live2d.Live2DModel.from(cubism4Model, { autoInteract: eye_bool })
      ]);
      PIXI.live2d.models = models;

      models.forEach((model) => {
        app.stage.addChild(model);
        const scaleX = (innerWidth) / model.width;
        const scaleY = (innerHeight) / model.height;
        model.scale.set(Math.min(scaleX, scaleY));
        model.y = innerHeight * 0.1;
        draggable(model);
      });

      const model4 = models[0];
      model4.x = innerWidth / 2;

      model4.on("hit", (hitAreas) => {
        if (hitAreas.includes("Body")) {
          model4.motion("Tap");
        }
        if (hitAreas.includes("Head")) {
          model4.expression();
        }
      });

      $("#update_bg").click(function () {
        var radioValue = $("input[name='options']:checked").val();
        setCookie("bg_con", radioValue, 1024);
        setCookie("bg_color", $("#bg_color").val(), 1024);
        location.reload();
      });

      $("#update_model").click(function () {
        axios.get('/edit_config', {
          params: { "model_path": $("#model_list").val() }
        })
          .then(response => {
            console.log(response.data);
            location.reload();
          })
          .catch(error => {
            console.error(error);
            alert(error);
          });
      });

      $("#play").click(function () {
        talk(model4, "./Keira.wav");
      });

      // 当按下 "q" 键时触发
      $(document).keydown(function (event) {
        if (event.which === 81) {
          $("#input_audio").mousedown();
        }
      });

      // 当释放 "q" 键时触发
      $(document).keyup(function (event) {
        if (event.which === 81) {
          $("#input_audio").mouseup();
        }
      });

      let mediaRecorder;
      let chunks = [];

      $("#input_audio").mousedown(function () {
        $(this).addClass("pressed").removeClass("released");

        navigator.mediaDevices.getUserMedia({ audio: true })
          .then(stream => {
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.start();

            const timeout = setTimeout(() => {
              mediaRecorder.stop();
              stream.getTracks().forEach(track => track.stop());
            }, 5000);

            mediaRecorder.addEventListener('dataavailable', event => {
              chunks.push(event.data);
            });

            mediaRecorder.addEventListener('stop', () => {
              clearTimeout(timeout);
              const audioBlob = new Blob(chunks, { type: 'audio/wav' });
              chunks = [];
              getText(audioBlob)

              // Play the audio by Live2D
              // const audioUrl = URL.createObjectURL(audioBlob);
              // const model4 = PIXI.live2d.models[0];
              // talk(model4, audioUrl);
            });
          })
          .catch(error => {
            console.error('Error accessing microphone:', error);
          });
      });

      $("#input_audio").mouseup(function () {
        $(this).addClass("released").removeClass("pressed");

        if (mediaRecorder && mediaRecorder.state === 'recording') {
          mediaRecorder.stop();
          // 发送音频文件给接口
          // sendAudioToServer();
        }
      });


      const getText = async (audioBlob) => {
        const formData = new FormData();
        formData.append('audio', audioBlob, 'audio.wav');

        const response = await fetch('http://localhost:8080/process_audio', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error('Network response was not ok');
        }

        console.log("Call LLM done___");
        const textStream = response.body;
        await processText(textStream);
      };

      const processText = async (textStream) => {
        const textReader = textStream.getReader();
        const decoder = new TextDecoder('utf-8');
        let done = false;

        while (!done) {
          const { value, done: doneReading } = await textReader.read();
          done = doneReading;
          const chunk = decoder.decode(value, { stream: true });
          console.log(chunk);
          if (chunk.trim() !== '') {
            await handleTextChunk(chunk.trim());
          }
        }
      };

      const handleTextChunk = async (text) => {
        const model4 = PIXI.live2d.models[0];

        return new Promise((resolve) => {
          speechSynthesizer.speakTextAsync(
            text,
            async (result) => {
              if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                console.log('Speech synthesis completed.');
                const audioBuffer = await audioContext.decodeAudioData(result.audioData);
                const audioUrl = await audioBufferToUrl(audioBuffer);
                await playAudio(model4, audioUrl);
                resolve();

              }
            },
            (error) => {
              console.error(`Speech synthesis error: ${error}`);
              resolve();
            }
          );
        });
      };

      const playAudio = (model, audioUrl) => {
        return new Promise((resolve) => {
          const audio = new Audio(audioUrl);
          audio.onended = () => {
            resolve();
          };
          talk(model, audioUrl);
          audio.play();
        });
      };

      const audioBufferToUrl = async (audioBuffer) => {
        const wav = audioBufferToWav(audioBuffer);
        const blob = new Blob([wav], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);
        return url;
      };

      const audioBufferToWav = (buffer) => {
        const numOfChan = buffer.numberOfChannels;
        const length = buffer.length * (numOfChan === 2 ? 4 : 2) + 44;
        const bufferInfo = new ArrayBuffer(length);
        const view = new DataView(bufferInfo);
        const channels = [];
        let offset = 0;
        let pos = 0;

        // write WAVE header
        writeUint32(0x46464952); // "RIFF"
        writeUint32(length - 8); // file length - 8
        writeUint32(0x45564157); // "WAVE"

        writeUint32(0x20746d66); // "fmt " chunk
        writeUint32(16); // length = 16
        writeUint16(1); // PCM (uncompressed)
        writeUint16(numOfChan);
        writeUint32(buffer.sampleRate);
        writeUint32(buffer.sampleRate * (numOfChan === 2 ? 4 : 2)); // avg. bytes/sec
        writeUint16(numOfChan === 2 ? 4 : 2); // block-align
        writeUint16(16); // 16-bit (hardcoded in this demo)

        writeUint32(0x61746164); // "data" - chunk
        writeUint32(length - pos - 4); // chunk length

        // write interleaved data
        for (let i = 0; i < numOfChan; i++) {
          channels.push(buffer.getChannelData(i));
        }

        while (pos < length) {
          for (let i = 0; i < numOfChan; i++) {
            // interleave channels
            let sample = Math.max(-1, Math.min(1, channels[i][offset])); // clamp
            sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0; // scale to 16-bit signed int
            view.setInt16(pos, sample, true); // write 16-bit sample
            pos += 2;
          }
          offset++; // next source sample
        }

        return bufferInfo;

        function writeUint16(data) {
          view.setUint16(pos, data, true);
          pos += 2;
        }

        function writeUint32(data) {
          view.setUint32(pos, data, true);
          pos += 4;
        }
      };

      const playAudioAndDriveModel = async (model, audioBuffer) => {
        const wavBuffer = audioBufferToWav(audioBuffer);
        const blob = new Blob([wavBuffer], { type: 'audio/wav' });
        const url = URL.createObjectURL(blob);

        talk(model, url);
      };

      const talk = (model, audioUrl) => {
        var volume = 1;
        var expression = 8;
        var resetExpression = true;
        var crossOrigin = "anonymous";

        model.speak(audioUrl, { volume: volume, expression: expression, resetExpression: resetExpression, crossOrigin: crossOrigin });
      };

      const synthesizer = {
        speakTextAsync: async (text) => {
          return new Promise((resolve, reject) => {
            speechSynthesizer.speakTextAsync(
              text,
              async (result) => {
                if (result.reason === SpeechSDK.ResultReason.SynthesizingAudioCompleted) {
                  const audioBuffer = await audioContext.decodeAudioData(result.audioData);
                  resolve({ audioBuffer });
                } else {
                  reject(new Error(`Speech synthesis failed: ${result.errorDetails}`));
                }
              },
              (error) => {
                reject(new Error(`Speech synthesis error: ${error}`));
              }
            );
          });
        }
      };


    })();


    // function talk(model, audio) {
    //   var audio_link = audio;
    //   var volume = 1;
    //   var expression = 8;
    //   var resetExpression = true;
    //   var crossOrigin = "anonymous";

    //   model.speak(audio_link, { volume: volume, expression: expression, resetExpression: resetExpression, crossOrigin: crossOrigin })
    //   model.speak(audio_link)
    //   model.speak(audio_link, { volume: volume })
    //   model.speak(audio_link, { expression: expression, resetExpression: resetExpression })
    // }

    function draggable(model) {
      model.buttonMode = true;
      model.on("pointerdown", (e) => {
        model.dragging = true;
        model._pointerX = e.data.global.x - model.x;
        model._pointerY = e.data.global.y - model.y;
      });
      model.on("pointermove", (e) => {
        if (model.dragging) {
          model.position.x = e.data.global.x - model._pointerX;
          model.position.y = e.data.global.y - model._pointerY;
        }
      });
      model.on("pointerupoutside", () => {
        model.dragging = false;
      });
      model.on("pointerup", () => {
        model.dragging = false;
      });
    }
  </script>
</body>

</html>